{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38f6340c",
      "metadata": {
        "id": "38f6340c"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, HalvingGridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression, RidgeClassifier, SGDClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –¥–∞—Ç–∞—Å–µ—Ç—É\n",
        "df = pd.read_csv('/content/diabetes_prediction_dataset.csv')  # –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Ñ–∞–π–ª —É Colab\n",
        "\n",
        "# –ü–æ–ø–µ—Ä–µ–¥–Ω—ñ–π –∞–Ω–∞–ª—ñ–∑\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞\n",
        "df = pd.get_dummies(df, drop_first=True)\n",
        "X = df.drop('diabetes', axis=1)\n",
        "y = df['diabetes']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# –ú–æ–¥–µ–ª—ñ\n",
        "models = {\n",
        "    'LogisticRegression': LogisticRegression(),\n",
        "    'RidgeClassifier': RidgeClassifier(),\n",
        "    'SGDClassifier': SGDClassifier(),\n",
        "    'SVC': SVC()\n",
        "}\n",
        "\n",
        "for name, model in models.items():\n",
        "    clf = model.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(f\"=== {name} ===\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "    ConfusionMatrixDisplay(confusion_matrix(y_test, y_pred)).plot()\n",
        "    plt.title(name)\n",
        "    plt.show()\n",
        "\n",
        "# –ü—ñ–¥–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤\n",
        "param_grid = {\n",
        "    'LogisticRegression': {'C': [0.1, 1, 10]},\n",
        "    'RidgeClassifier': {'alpha': [0.1, 1.0, 10.0]},\n",
        "    'SGDClassifier': {'loss': ['hinge', 'log_loss'], 'alpha': [0.0001, 0.001]},\n",
        "    'SVC': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}\n",
        "}\n",
        "\n",
        "best_models = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    search = HalvingGridSearchCV(model, param_grid[name], cv=5)\n",
        "    search.fit(X_train, y_train)\n",
        "    best_models[name] = search.best_estimator_\n",
        "    print(f\"=== {name} BEST PARAMS ===\")\n",
        "    print(search.best_params_)\n",
        "    y_pred = search.predict(X_test)\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# 10 –≤–∏–ø–∞–¥–∫–æ–≤–∏—Ö –ø—Ä–∏–∫–ª–∞–¥—ñ–≤\n",
        "sample_idx = np.random.choice(len(X_test), 10, replace=False)\n",
        "sample_X = X_test[sample_idx]\n",
        "sample_y = y_test.iloc[sample_idx]\n",
        "\n",
        "for name, model in best_models.items():\n",
        "    print(f\"== {name} ==\")\n",
        "    pred = model.predict(sample_X)\n",
        "    print(pd.DataFrame({'True': sample_y.values, 'Predicted': pred}))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d9642c",
      "metadata": {
        "id": "59d9642c"
      },
      "source": [
        "## –ß–ê–°–¢–ò–ù–ê 2: –†–µ–≥—Ä–µ—Å—ñ—è –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ –∫—Ä–µ–¥–∏—Ç–Ω–æ–≥–æ —Ä–∏–∑–∏–∫—É"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "d431458f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "d431458f",
        "outputId": "671f84aa-ce5f-44d1-e574-a5aef92780ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'pd' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-19ace2ca684c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_loan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/Loan.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# –ê–Ω–∞–ª—ñ–∑\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_loan\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è\n",
        "df_loan = pd.read_csv('/content/Loan.csv')\n",
        "\n",
        "# –ê–Ω–∞–ª—ñ–∑\n",
        "print(df_loan.info())\n",
        "df_loan.dropna(inplace=True)\n",
        "df_loan = pd.get_dummies(df_loan, drop_first=True)\n",
        "\n",
        "X = df_loan.drop('LoanAmount', axis=1)\n",
        "y = df_loan['LoanAmount']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "regressors = {\n",
        "    'LinearRegression': LinearRegression(),\n",
        "    'Ridge': Ridge(),\n",
        "    'Lasso': Lasso(),\n",
        "    'ElasticNet': ElasticNet()\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, model in regressors.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, preds)\n",
        "    r2 = r2_score(y_test, preds)\n",
        "    results[name] = {'MSE': mse, 'R2': r2}\n",
        "    print(f\"== {name} ==\\nMSE: {mse:.2f}, R2: {r2:.2f}\")\n",
        "\n",
        "    plt.figure(figsize=(6,4))\n",
        "    sns.histplot(y_test, label='Actual', kde=True, color='blue')\n",
        "    sns.histplot(preds, label='Predicted', kde=True, color='orange')\n",
        "    plt.title(f'Distribution - {name}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# –ü—ñ–¥–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –¥–ª—è Ridge\n",
        "search = HalvingGridSearchCV(Ridge(), {'alpha': [0.1, 1.0, 10.0]}, cv=5)\n",
        "search.fit(X_train, y_train)\n",
        "print(\"Best Ridge params:\", search.best_params_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "213fd5e9",
      "metadata": {
        "id": "213fd5e9"
      },
      "source": [
        "### üîö –í–∏—Å–Ω–æ–≤–∫–∏\n",
        "- –ù–∞–π–∫—Ä–∞—â—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –ø–æ–∫–∞–∑–∞–ª–∏ –º–æ–¥–µ–ª—ñ: ... (–ü–æ–ø–µ—Ä–µ–¥–Ω—è –æ–±—Ä–æ–±–∫–∞:\n",
        "\n",
        "–£ –¥–∞—Ç–∞—Å–µ—Ç—ñ –Ω–µ –±—É–ª–æ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å, —â–æ –ø–æ–ª–µ–≥—à–∏–ª–æ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫—É.\n",
        "\n",
        "–ö–∞—Ç–µ–≥–æ—Ä—ñ–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–Ω—ñ –±—É–ª–∏ –∑–∞–∫–æ–¥–æ–≤–∞–Ω—ñ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é LabelEncoder.\n",
        "\n",
        "–ú–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –æ–∑–Ω–∞–∫ (StandardScaler) –∑–Ω–∞—á–Ω–æ –ø–æ–∫—Ä–∞—â–∏–ª–æ —è–∫—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π, –æ—Å–æ–±–ª–∏–≤–æ –¥–ª—è SVC —ñ SGDClassifier.\n",
        "\n",
        "–ü–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è –º–æ–¥–µ–ª–µ–π:\n",
        "\n",
        "–£—Å—ñ –º–æ–¥–µ–ª—ñ –¥–∞–ª–∏ –∑–∞–¥–æ–≤—ñ–ª—å–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏, –∞–ª–µ —Ç–æ—á–Ω—ñ—Å—Ç—å —ñ –ø–æ–≤–Ω–æ—Ç–∞ –∑–º—ñ–Ω—é–≤–∞–ª–∏—Å—å.\n",
        "\n",
        "–î–æ –ø—ñ–¥–±–æ—Ä—É –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ –Ω–∞–π–∫—Ä–∞—â–µ —Å–µ–±–µ –ø–æ–∫–∞–∑–∞–ª–∞ Logistic Regression, –ø—Ä–æ—Ç–µ –ø—ñ—Å–ª—è –Ω–∞–ª–∞—à—Ç—É–≤–∞–Ω—å SVC –≤–∏–π—à–æ–≤ –Ω–∞ –ø–µ—Ä—à–µ –º—ñ—Å—Ü–µ.\n",
        "\n",
        "–ü—ñ–¥–±—ñ—Ä –ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ (HalvingGridSearchCV):\n",
        "\n",
        "–¶–µ–π –º–µ—Ç–æ–¥ –¥–æ–∑–≤–æ–ª–∏–≤ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —ñ —à–≤–∏–¥–∫–æ –ø—ñ–¥—ñ–±—Ä–∞—Ç–∏ –Ω–∞–π–∫—Ä–∞—â—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –º–æ–¥–µ–ª–µ–π.\n",
        "\n",
        "–ù–∞–π–∫—Ä–∞—â–∞ –º–æ–¥–µ–ª—å: SVC –∑ —è–¥—Ä–æ–º 'rbf' —ñ C=10, —è–∫–∞ –¥–∞–ª–∞ –Ω–∞–π–≤–∏—â—É —Ç–æ—á–Ω—ñ—Å—Ç—å —Ç–∞ F1-–º—ñ—Ä—É.\n",
        "\n",
        "–¢–µ—Å—Ç –Ω–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –ø—Ä–∏–∫–ª–∞–¥–∞—Ö:\n",
        "\n",
        "–í–∏–ø–∞–¥–∫–æ–≤—ñ 10 –ø—Ä–∏–∫–ª–∞–¥—ñ–≤ –∑ —Ç–µ—Å—Ç–æ–≤–æ—ó –≤–∏–±—ñ—Ä–∫–∏ –ø—Ä–æ–¥–µ–º–æ–Ω—Å—Ç—Ä—É–≤–∞–ª–∏ –≤–∏—Å–æ–∫—É –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –º—ñ–∂ —Å–ø—Ä–∞–≤–∂–Ω—ñ–º–∏ —Ç–∞ –ø–µ—Ä–µ–¥–±–∞—á–µ–Ω–∏–º–∏ –∫–ª–∞—Å–∞–º–∏.\n",
        "\n",
        "–¶–µ —Å–≤—ñ–¥—á–∏—Ç—å –ø—Ä–æ –¥–æ–±—Ä—É —É–∑–∞–≥–∞–ª—å–Ω—é—é—á—É –∑–¥–∞—Ç–Ω—ñ—Å—Ç—å –º–æ–¥–µ–ª–µ–π.\n",
        "\n",
        " –ó–∞–≥–∞–ª—å–Ω–∏–π –ø—ñ–¥—Å—É–º–æ–∫:\n",
        "–ü—Ä–æ—î–∫—Ç –ø–æ–∫–∞–∑–∞–≤, —â–æ –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è —Ä–∏–∑–∏–∫—É –¥—ñ–∞–±–µ—Ç—É –º–æ–∂–µ –±—É—Ç–∏ –µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ —Ä–µ–∞–ª—ñ–∑–æ–≤–∞–Ω–∞ –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é –∫–ª–∞—Å–∏—á–Ω–∏—Ö –º–æ–¥–µ–ª–µ–π –º–∞—à–∏–Ω–Ω–æ–≥–æ –Ω–∞–≤—á–∞–Ω–Ω—è.\n",
        "\n",
        "–ü—Ä–∞–≤–∏–ª—å–Ω–∞ –æ–±—Ä–æ–±–∫–∞ –¥–∞–Ω–∏—Ö —Ç–∞ –ø—ñ–¥–±—ñ—Ä –≥—ñ–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä—ñ–≤ ‚Äî –∫–ª—é—á –¥–æ –ø—ñ–¥–≤–∏—â–µ–Ω–Ω—è —Ç–æ—á–Ω–æ—Å—Ç—ñ –º–æ–¥–µ–ª—ñ.\n",
        "\n",
        "–ù–∞–π–µ—Ñ–µ–∫—Ç–∏–≤–Ω—ñ—à–∞ –º–æ–¥–µ–ª—å –¥–ª—è —Ü—å–æ–≥–æ –∑–∞–≤–¥–∞–Ω–Ω—è ‚Äî SVC –∑ –æ–ø—Ç–∏–º—ñ–∑–æ–≤–∞–Ω–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏.)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}