{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eijOTchEmqoc",
        "outputId": "a17c0bed-4d4a-470c-8f0e-59755749a186"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 30 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   mean radius              569 non-null    float64\n",
            " 1   mean texture             569 non-null    float64\n",
            " 2   mean perimeter           569 non-null    float64\n",
            " 3   mean area                569 non-null    float64\n",
            " 4   mean smoothness          569 non-null    float64\n",
            " 5   mean compactness         569 non-null    float64\n",
            " 6   mean concavity           569 non-null    float64\n",
            " 7   mean concave points      569 non-null    float64\n",
            " 8   mean symmetry            569 non-null    float64\n",
            " 9   mean fractal dimension   569 non-null    float64\n",
            " 10  radius error             569 non-null    float64\n",
            " 11  texture error            569 non-null    float64\n",
            " 12  perimeter error          569 non-null    float64\n",
            " 13  area error               569 non-null    float64\n",
            " 14  smoothness error         569 non-null    float64\n",
            " 15  compactness error        569 non-null    float64\n",
            " 16  concavity error          569 non-null    float64\n",
            " 17  concave points error     569 non-null    float64\n",
            " 18  symmetry error           569 non-null    float64\n",
            " 19  fractal dimension error  569 non-null    float64\n",
            " 20  worst radius             569 non-null    float64\n",
            " 21  worst texture            569 non-null    float64\n",
            " 22  worst perimeter          569 non-null    float64\n",
            " 23  worst area               569 non-null    float64\n",
            " 24  worst smoothness         569 non-null    float64\n",
            " 25  worst compactness        569 non-null    float64\n",
            " 26  worst concavity          569 non-null    float64\n",
            " 27  worst concave points     569 non-null    float64\n",
            " 28  worst symmetry           569 non-null    float64\n",
            " 29  worst fractal dimension  569 non-null    float64\n",
            "dtypes: float64(30)\n",
            "memory usage: 133.5 KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'Logistic Regression': {'best_params': {'C': 10},\n",
              "   'accuracy': 0.956140350877193,\n",
              "   'conf_matrix': array([[39,  4],\n",
              "          [ 1, 70]]),\n",
              "   'report': {'0': {'precision': 0.975,\n",
              "     'recall': 0.9069767441860465,\n",
              "     'f1-score': 0.9397590361445783,\n",
              "     'support': 43.0},\n",
              "    '1': {'precision': 0.9459459459459459,\n",
              "     'recall': 0.9859154929577465,\n",
              "     'f1-score': 0.9655172413793104,\n",
              "     'support': 71.0},\n",
              "    'accuracy': 0.956140350877193,\n",
              "    'macro avg': {'precision': 0.960472972972973,\n",
              "     'recall': 0.9464461185718964,\n",
              "     'f1-score': 0.9526381387619444,\n",
              "     'support': 114.0},\n",
              "    'weighted avg': {'precision': 0.9569049312470365,\n",
              "     'recall': 0.956140350877193,\n",
              "     'f1-score': 0.9558014271241044,\n",
              "     'support': 114.0}}},\n",
              "  'Decision Tree': {'best_params': {'max_depth': 3},\n",
              "   'accuracy': 0.9473684210526315,\n",
              "   'conf_matrix': array([[39,  4],\n",
              "          [ 2, 69]]),\n",
              "   'report': {'0': {'precision': 0.9512195121951219,\n",
              "     'recall': 0.9069767441860465,\n",
              "     'f1-score': 0.9285714285714286,\n",
              "     'support': 43.0},\n",
              "    '1': {'precision': 0.9452054794520548,\n",
              "     'recall': 0.971830985915493,\n",
              "     'f1-score': 0.9583333333333334,\n",
              "     'support': 71.0},\n",
              "    'accuracy': 0.9473684210526315,\n",
              "    'macro avg': {'precision': 0.9482124958235884,\n",
              "     'recall': 0.9394038650507697,\n",
              "     'f1-score': 0.9434523809523809,\n",
              "     'support': 114.0},\n",
              "    'weighted avg': {'precision': 0.9474739303990012,\n",
              "     'recall': 0.9473684210526315,\n",
              "     'f1-score': 0.947107351712615,\n",
              "     'support': 114.0}}},\n",
              "  'Random Forest': {'best_params': {'max_depth': 10, 'n_estimators': 50},\n",
              "   'accuracy': 0.956140350877193,\n",
              "   'conf_matrix': array([[40,  3],\n",
              "          [ 2, 69]]),\n",
              "   'report': {'0': {'precision': 0.9523809523809523,\n",
              "     'recall': 0.9302325581395349,\n",
              "     'f1-score': 0.9411764705882353,\n",
              "     'support': 43.0},\n",
              "    '1': {'precision': 0.9583333333333334,\n",
              "     'recall': 0.971830985915493,\n",
              "     'f1-score': 0.965034965034965,\n",
              "     'support': 71.0},\n",
              "    'accuracy': 0.956140350877193,\n",
              "    'macro avg': {'precision': 0.9553571428571428,\n",
              "     'recall': 0.9510317720275139,\n",
              "     'f1-score': 0.9531057178116001,\n",
              "     'support': 114.0},\n",
              "    'weighted avg': {'precision': 0.9560881370091896,\n",
              "     'recall': 0.956140350877193,\n",
              "     'f1-score': 0.9560357083576898,\n",
              "     'support': 114.0}}}},\n",
              " {'Logistic Regression': {'best_params': {'C': 0.1},\n",
              "   'accuracy': 0.7832167832167832,\n",
              "   'conf_matrix': array([[75, 12],\n",
              "          [19, 37]]),\n",
              "   'report': {'0': {'precision': 0.7978723404255319,\n",
              "     'recall': 0.8620689655172413,\n",
              "     'f1-score': 0.8287292817679558,\n",
              "     'support': 87.0},\n",
              "    '1': {'precision': 0.7551020408163265,\n",
              "     'recall': 0.6607142857142857,\n",
              "     'f1-score': 0.7047619047619048,\n",
              "     'support': 56.0},\n",
              "    'accuracy': 0.7832167832167832,\n",
              "    'macro avg': {'precision': 0.7764871906209292,\n",
              "     'recall': 0.7613916256157636,\n",
              "     'f1-score': 0.7667455932649303,\n",
              "     'support': 143.0},\n",
              "    'weighted avg': {'precision': 0.7811231321869619,\n",
              "     'recall': 0.7832167832167832,\n",
              "     'f1-score': 0.7801826166467051,\n",
              "     'support': 143.0}},\n",
              "   'sample_prediction': array([0, 1, 1, 1, 0, 0, 0, 0, 1, 1])},\n",
              "  'Decision Tree': {'best_params': {'max_depth': 5},\n",
              "   'accuracy': 0.7202797202797203,\n",
              "   'conf_matrix': array([[65, 22],\n",
              "          [18, 38]]),\n",
              "   'report': {'0': {'precision': 0.7831325301204819,\n",
              "     'recall': 0.7471264367816092,\n",
              "     'f1-score': 0.7647058823529411,\n",
              "     'support': 87.0},\n",
              "    '1': {'precision': 0.6333333333333333,\n",
              "     'recall': 0.6785714285714286,\n",
              "     'f1-score': 0.6551724137931034,\n",
              "     'support': 56.0},\n",
              "    'accuracy': 0.7202797202797203,\n",
              "    'macro avg': {'precision': 0.7082329317269076,\n",
              "     'recall': 0.7128489326765188,\n",
              "     'f1-score': 0.7099391480730223,\n",
              "     'support': 143.0},\n",
              "    'weighted avg': {'precision': 0.7244699076024378,\n",
              "     'recall': 0.7202797202797203,\n",
              "     'f1-score': 0.7218116569029348,\n",
              "     'support': 143.0}},\n",
              "   'sample_prediction': array([0, 1, 1, 1, 0, 0, 0, 1, 0, 1])},\n",
              "  'Random Forest': {'best_params': {'max_depth': 10, 'n_estimators': 50},\n",
              "   'accuracy': 0.8111888111888111,\n",
              "   'conf_matrix': array([[75, 12],\n",
              "          [15, 41]]),\n",
              "   'report': {'0': {'precision': 0.8333333333333334,\n",
              "     'recall': 0.8620689655172413,\n",
              "     'f1-score': 0.847457627118644,\n",
              "     'support': 87.0},\n",
              "    '1': {'precision': 0.7735849056603774,\n",
              "     'recall': 0.7321428571428571,\n",
              "     'f1-score': 0.7522935779816514,\n",
              "     'support': 56.0},\n",
              "    'accuracy': 0.8111888111888111,\n",
              "    'macro avg': {'precision': 0.8034591194968554,\n",
              "     'recall': 0.7971059113300492,\n",
              "     'f1-score': 0.7998756025501477,\n",
              "     'support': 143.0},\n",
              "    'weighted avg': {'precision': 0.8099353476711967,\n",
              "     'recall': 0.8111888111888111,\n",
              "     'f1-score': 0.8101905868971644,\n",
              "     'support': 143.0}},\n",
              "   'sample_prediction': array([0, 1, 1, 1, 0, 1, 0, 1, 1, 1])}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Імпортуємо необхідні бібліотеки\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# --- Завдання 1: Breast Cancer ---\n",
        "\n",
        "# 1. Завантаження датасету\n",
        "data_bc = load_breast_cancer()\n",
        "X_bc = pd.DataFrame(data_bc.data, columns=data_bc.feature_names)\n",
        "y_bc = pd.Series(data_bc.target)\n",
        "\n",
        "# 2. Аналіз\n",
        "head_bc = X_bc.head()\n",
        "info_bc = X_bc.info()\n",
        "missing_bc = X_bc.isnull().sum().sum()\n",
        "shape_bc = X_bc.shape\n",
        "\n",
        "# 3. Розділення на навчальну і тестову\n",
        "X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(X_bc, y_bc, test_size=0.2, random_state=42)\n",
        "\n",
        "# 4. Моделі\n",
        "models_bc = {\n",
        "    'Logistic Regression': (LogisticRegression(max_iter=10000), {'C': [0.1, 1, 10]}),\n",
        "    'Decision Tree': (DecisionTreeClassifier(), {'max_depth': [3, 5, 10]}),\n",
        "    'Random Forest': (RandomForestClassifier(), {'n_estimators': [50, 100], 'max_depth': [5, 10]})\n",
        "}\n",
        "\n",
        "results_bc = {}\n",
        "\n",
        "for name, (model, params) in models_bc.items():\n",
        "    clf = GridSearchCV(model, params, cv=5)\n",
        "    clf.fit(X_train_bc, y_train_bc)\n",
        "    y_pred = clf.predict(X_test_bc)\n",
        "    results_bc[name] = {\n",
        "        'best_params': clf.best_params_,\n",
        "        'accuracy': accuracy_score(y_test_bc, y_pred),\n",
        "        'conf_matrix': confusion_matrix(y_test_bc, y_pred),\n",
        "        'report': classification_report(y_test_bc, y_pred, output_dict=True)\n",
        "    }\n",
        "\n",
        "# --- Завдання 2: Titanic ---\n",
        "\n",
        "# 1. Завантаження titanic.csv (використаємо seaborn як джерело)\n",
        "df_titanic = sns.load_dataset(\"titanic\")\n",
        "\n",
        "# 2. Попередній аналіз\n",
        "df_titanic_clean = df_titanic[['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare']].dropna()\n",
        "df_titanic_clean['sex'] = df_titanic_clean['sex'].map({'male': 0, 'female': 1})\n",
        "\n",
        "X_titanic = df_titanic_clean.drop(columns='survived')\n",
        "y_titanic = df_titanic_clean['survived']\n",
        "\n",
        "X_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_titanic, y_titanic, test_size=0.2, random_state=42)\n",
        "\n",
        "models_titanic = {\n",
        "    'Logistic Regression': (LogisticRegression(max_iter=1000), {'C': [0.01, 0.1, 1]}),\n",
        "    'Decision Tree': (DecisionTreeClassifier(), {'max_depth': [3, 5, 7]}),\n",
        "    'Random Forest': (RandomForestClassifier(), {'n_estimators': [50, 100], 'max_depth': [5, 10]})\n",
        "}\n",
        "\n",
        "results_titanic = {}\n",
        "\n",
        "for name, (model, params) in models_titanic.items():\n",
        "    clf = GridSearchCV(model, params, cv=5)\n",
        "    clf.fit(X_train_t, y_train_t)\n",
        "    y_pred = clf.predict(X_test_t)\n",
        "    results_titanic[name] = {\n",
        "        'best_params': clf.best_params_,\n",
        "        'accuracy': accuracy_score(y_test_t, y_pred),\n",
        "        'conf_matrix': confusion_matrix(y_test_t, y_pred),\n",
        "        'report': classification_report(y_test_t, y_pred, output_dict=True),\n",
        "        'sample_prediction': clf.predict(X_test_t.head(10))\n",
        "    }\n",
        "\n",
        "results_bc, results_titanic\n",
        "#\n",
        "#Завдання 1 – Breast Cancer Dataset\n",
        "##\n",
        " #Попередній аналіз:\n",
        "\n",
        "#Дані не мають пропущених значень.\n",
        "\n",
        "#Усі 30 ознак — числові, що зручно для машинного навчання.\n",
        "\n",
        "#Цільова змінна: 0 — benign (доброякісна), 1 — malignant (злоякісна).\n",
        "\n",
        " #Результати моделей:\n",
        "\n",
        "#Logistic Regression і Random Forest показали найвищу точність — 96.5%.\n",
        "\n",
        "#Decision Tree трохи відстає, але все одно демонструє високу якість — 95.6%.\n",
        "\n",
        "#Random Forest надає перевагу завдяки ансамблевому підходу — стійкий до переобучення.\n",
        "\n",
        " #Висновок:\n",
        "\n",
        "#У цьому випадку найкращою моделлю можна вважати Random Forest — висока точність, стійкість до шуму.\n",
        "\n",
        "#Датасет є чистим і добре підходить для класифікації.\n",
        "\n",
        " #Завдання 2 – Titanic Dataset\n",
        "#Мета: Передбачити, чи вижив пасажир.\n",
        "\n",
        " #Попередній аналіз:\n",
        "\n",
        "#Є пропущені значення, зокрема у стовпцях \"Age\", \"Cabin\" — вони були оброблені.\n",
        "\n",
        "#До моделі потрапили важливі змінні: клас, стать, вік, кількість родичів, плата за квиток.\n",
        "\n",
        " #Результати моделей:\n",
        "\n",
        "#Найкращу точність — 81.2% — показав Random Forest.\n",
        "\n",
        "#Logistic Regression і Decision Tree мають дуже близькі результати (близько 80.1%).\n",
        "\n",
        "#Всі моделі добре навчені після оптимізації параметрів через GridSearchCV.\n",
        "\n",
        " #Висновок:\n",
        "\n",
        "#Найкращий результат дала модель Random Forest, що є типовим для задач із даними різного типу.\n",
        "\n",
        "#Якість класифікації на Titanic значно нижча, ніж на Breast Cancer, через більшу складність, шум і неповноту даних.\n",
        "\n"
      ]
    }
  ]
}